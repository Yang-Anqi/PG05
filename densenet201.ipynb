{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from PIL import Image\n",
    "from IPython import display\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code blocks are organized in the following sequence: \n",
    "\n",
    "Data Preprocessing → Model and Function Definition → Model Training → Model Testing → Viewing Test Results. \n",
    "\n",
    "This code uses DenseNet201 as pretrained models and includes implementation of Grad-CAM visualization modules.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "file_dir = r'your-dataset-path-directory'  # e.g., '/home/user/dataset' \n",
    "train_dir = os.path.join(file_dir, 'your-trainsubset-name')\n",
    "test_dir = os.path.join(file_dir, 'your-testsubset-name')\n",
    "\"\"\"\n",
    "The dataset is stored in the following format:\n",
    "\n",
    "file_dir/\n",
    "├── train_dir/\n",
    "│    ├── Normal/\n",
    "│    │     ├── image1.jpg\n",
    "│    │     ├── image2.jpg\n",
    "│    │     └── ...\n",
    "│    ├── Pneumonia-Bacterial/\n",
    "│    │     ├── image1.jpg\n",
    "│    │     ├── image2.jpg\n",
    "│    │     └── ...\n",
    "│    └── Pneumonia-Viral/\n",
    "│            ├── image1.jpg\n",
    "│            ├── image2.jpg\n",
    "│            └── ...\n",
    "│\n",
    "└── test_dir/\n",
    "    ├── Normal/\n",
    "    │     ├── image1.jpg\n",
    "    │     └── ...\n",
    "    ├── Pneumonia-Bacterial/\n",
    "    │     ├── image1.jpg\n",
    "    │     ├── image2.jpg\n",
    "    │     └── ...\n",
    "    └── Pneumonia-Viral/\n",
    "           ├── image1.jpg\n",
    "           ├── image2.jpg\n",
    "           └── ...           \n",
    "\"\"\"\n",
    "\n",
    "img_size = 512\n",
    "batch_size = 4\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and Function Definition\n",
    "\n",
    "# model definition\n",
    "def create_model():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = models.densenet201(pretrained=True)\n",
    "    num_features = model.classifier.in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(num_features, num_features // 2),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(num_features // 2, 3) \n",
    "    )\n",
    "    return model.to(device)\n",
    "\n",
    "# Grad-CAM visualization function definition\n",
    "def grad_cam(model, img_tensor, target_layer):\n",
    "    model.eval()\n",
    "    img_tensor = img_tensor.to(device)\n",
    "    features = None\n",
    "    gradients = None\n",
    "\n",
    "    def forward_hook(module, input, output):\n",
    "        nonlocal features\n",
    "        features = output\n",
    "\n",
    "    def backward_hook(module, grad_in, grad_out):\n",
    "        nonlocal gradients\n",
    "        gradients = grad_out[0]\n",
    "\n",
    "    handle_forward = target_layer.register_forward_hook(forward_hook)\n",
    "    handle_backward = target_layer.register_backward_hook(backward_hook)\n",
    "\n",
    "    output = model(img_tensor)\n",
    "    pred_class = output.argmax(dim=1)\n",
    "    loss = output[0, pred_class]\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "    features = features[0]\n",
    "    for i in range(features.shape[0]):\n",
    "        features[i, :, :] *= pooled_gradients[i]\n",
    "\n",
    "    heatmap = features.detach().cpu().numpy().mean(axis=0)\n",
    "    heatmap = np.maximum(heatmap, 0)  \n",
    "    max_value = np.max(heatmap)\n",
    "    if max_value > 0:\n",
    "        heatmap /= max_value\n",
    "    else:\n",
    "        heatmap = np.zeros_like(heatmap)  \n",
    "\n",
    "    handle_forward.remove()\n",
    "    handle_backward.remove()\n",
    "\n",
    "    return heatmap\n",
    "\n",
    "def plot_grad_cam(img_path, model, target_layer):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (img_size, img_size))\n",
    "    img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))  \n",
    "    img_tensor = transform_val(img).unsqueeze(0)\n",
    "\n",
    "    heatmap = grad_cam(model, img_tensor, target_layer)\n",
    "    heatmap = cv2.resize(heatmap, img.size)  \n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "    if isinstance(img, Image.Image):  \n",
    "        img = np.array(img)  # 转换为 NumPy 数组\n",
    "    superimposed_img = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Grad-CAM\")\n",
    "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "\n",
    "# If you want to save the model, uncomment the following line:\n",
    "\n",
    "# model_path_dir = f\"your-model-path-directory\"  # e.g., '/home/user/model'\n",
    "# current_time = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "# model_name = f\"resnet18_time{current_time}.pth\"\n",
    "# model_path = os.path.join(model_path_dir, model_name)\n",
    "\n",
    "model = create_model()\n",
    "train_dataset = datasets.ImageFolder(train_dir)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "folds = list(kf.split(range(len(train_dataset))))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 4\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "for fold, (train_idx, val_idx) in enumerate(folds):\n",
    "    print(f\"  Fold {fold+1}/5---------------------------------------------------------------------------\")\n",
    "    train_dataset = datasets.ImageFolder(train_dir)\n",
    "    train_subset = Subset(train_dataset, train_idx)\n",
    "    val_subset = Subset(train_dataset, val_idx)\n",
    "    train_subset.dataset.transform = transform_train\n",
    "    val_subset.dataset.transform = transform_val\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    for epoch in range(epochs):  \n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        for inputs, labels in train_loader:  \n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "        train_acc = train_correct / train_total\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device) \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "            val_acc = val_correct / val_total\n",
    "        print(f\"   Epoch {epoch+1}/{epochs}, Train Loss: {train_loss/len(train_loader):.4f}, \"\n",
    "            f\"Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {val_correct/val_total:.4f}\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "# If you want to save the model, uncomment the following line:\n",
    "# torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Testing  (different models' testing codes are not the same)\n",
    "# make sure to uncomment the model you want to test and comment out the others\n",
    "\n",
    "# If you want to test the saved model, uncomment the following line:\n",
    "# make sure the model you want to test is the same as the one you trained\n",
    "# you can uncomment corresponding model definition in \"Model and Function Definition\" part and run it again\n",
    "# model_path_dir = f\"your-model-path-directory\"  # e.g., '/home/user/model'\n",
    "# model_name = f\"your-model-name.pth\" \n",
    "# model_path = os.path.join(model_path_dir, model_name)\n",
    "# model = create_model()\n",
    "# model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "file_dir = r'your-dataset-path-directory'  # e.g., '/home/user/dataset'\n",
    "test_dir = os.path.join(file_dir, 'your-testsubset-name')\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform_val)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "misclassified_images = []\n",
    "misclassified_labels = []\n",
    "misclassified_predictions = []\n",
    "\n",
    "trueclassified_images = []\n",
    "trueclassified_labels = []\n",
    "trueclassified_predictions = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)  \n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item() \n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == predicted[i]:\n",
    "                misclassified_images.append(inputs[i].cpu())\n",
    "                misclassified_labels.append(labels[i].cpu().item())\n",
    "                misclassified_predictions.append(predicted[i].cpu().item())\n",
    "            else:\n",
    "                trueclassified_images.append(inputs[i].cpu())\n",
    "                trueclassified_labels.append(labels[i].cpu().item())\n",
    "                trueclassified_predictions.append(predicted[i].cpu().item())\n",
    "test_acc = 100. * correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing Test Results-confusion matrix and recall\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_dataset.classes)\n",
    "tp = cm[1, 1]+ cm[2, 2]\n",
    "fn = cm[1, 0]+ cm[2, 0]\n",
    "recall = tp / (tp + fn)*100 if (tp + fn) > 0 else 0\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "plt.figure(figsize=(8, 8))\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing Test Results-Grad-CAM visualization for misclassified images or trueclassified images\n",
    "\n",
    "combined_heatmap = np.zeros((img_size, img_size))\n",
    "target_layer = model.resnet.layer4[1].conv2\n",
    "for img_tensor in trueclassified_images: # choose misclassified_images or trueclassified_images\n",
    "    heatmap = grad_cam(model, img_tensor.unsqueeze(0).to(device), target_layer) \n",
    "    heatmap_resized = cv2.resize(heatmap, (img_size, img_size))\n",
    "    combined_heatmap += heatmap_resized\n",
    "combined_heatmap /= len(trueclassified_images) # choose misclassified_images or trueclassified_images\n",
    "combined_heatmap = np.uint8(255 * (combined_heatmap / np.max(combined_heatmap))) \n",
    "combined_heatmap = cv2.applyColorMap(combined_heatmap, cv2.COLORMAP_JET)\n",
    "img = np.ones((img_size, img_size, 3), dtype=np.uint8) * 255\n",
    "superimposed_img = cv2.addWeighted((img * 255).astype(np.uint8), 0.6, combined_heatmap, 0.4, 0)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"Combined Grad-CAM Heatmap\")\n",
    "plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing Test Results-Grad-CAM visualization for random misclassified&trueclassified images\n",
    "\n",
    "# left is input image, right is Grad-CAM result\n",
    "max_num = 10 # choose the most number of images to show at once\n",
    "class_names = test_dataset.classes\n",
    "num_images_to_show = min(max_num, len(misclassified_images))  \n",
    "plt.figure(figsize=(15, 30))\n",
    "for i in range(num_images_to_show):\n",
    "    j = i + max_num*1  # adjust \"*num\" to show more images\n",
    "    img = misclassified_images[j]\n",
    "    img = img.permute(1, 2, 0).numpy()  \n",
    "    img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "    img = np.clip(img, 0, 1) \n",
    "    heatmap = grad_cam(model, misclassified_images[j].unsqueeze(0).to(device), target_layer)\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    superimposed_img = cv2.addWeighted((img * 255).astype(np.uint8), 0.6, heatmap, 0.4, 0)\n",
    "\n",
    "    plt.subplot(num_images_to_show, 2, 2 * i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"{j}:True: {class_names[misclassified_labels[j]]}, Pred: {class_names[misclassified_predictions[j]]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(num_images_to_show, 2, 2 * i + 2)\n",
    "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Grad-CAM\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ST5188",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
