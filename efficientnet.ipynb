{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e7b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import KFold\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.transforms import functional as F\n",
    "import timm\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141f85bb",
   "metadata": {},
   "source": [
    "The code blocks are organized in the following sequence: \n",
    "\n",
    "Data Preprocessing → Model and Function Definition → Model Training → Model Testing → Viewing Test Results. \n",
    "\n",
    "This code uses EfficientNet_b0 as pretrained models and includes implementations of custom feature extractors, Gabor filters, and Grad-CAM visualization modules. The implementation of different functionalities can be seen in the code comments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c0865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "file_dir = r'your-dataset-path-directory'  # e.g., '/home/user/dataset' \n",
    "train_dir = os.path.join(file_dir, 'your-trainsubset-name')\n",
    "test_dir = os.path.join(file_dir, 'your-testsubset-name')\n",
    "\"\"\"\n",
    "The dataset is stored in the following format:\n",
    "\n",
    "file_dir/\n",
    "├── train_dir/\n",
    "│    ├── Normal/\n",
    "│    │     ├── image1.jpg\n",
    "│    │     ├── image2.jpg\n",
    "│    │     └── ...\n",
    "│    ├── Pneumonia-Bacterial/\n",
    "│    │     ├── image1.jpg\n",
    "│    │     ├── image2.jpg\n",
    "│    │     └── ...\n",
    "│    └── Pneumonia-Viral/\n",
    "│            ├── image1.jpg\n",
    "│            ├── image2.jpg\n",
    "│            └── ...\n",
    "│\n",
    "└── test_dir/\n",
    "    ├── Normal/\n",
    "    │     ├── image1.jpg\n",
    "    │     └── ...\n",
    "    ├── Pneumonia-Bacterial/\n",
    "    │     ├── image1.jpg\n",
    "    │     ├── image2.jpg\n",
    "    │     └── ...\n",
    "    └── Pneumonia-Viral/\n",
    "           ├── image1.jpg\n",
    "           ├── image2.jpg\n",
    "           └── ...           \n",
    "\"\"\"\n",
    "\n",
    "img_size = 512\n",
    "batch_size = 16\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986d6f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and Function Definition(①Default, ②CNN Block, ③gabor filters+ gabor_conv, ④gabor filters + CNN Block)\n",
    "# each model will be commented, and you can choose one of them to run\n",
    "# make sure to comment out other models once you choose one to run\n",
    "\n",
    "# model definition\n",
    "# ① Default EfficientNet-B0\n",
    "def create_model():\n",
    "    class CustomEfficientNet(nn.Module):\n",
    "        def __init__(self, num_classes=3):\n",
    "            super(CustomEfficientNet, self).__init__()\n",
    "            self.efficientnet = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "            in_features = self.efficientnet.classifier.in_features\n",
    "            self.efficientnet.classifier = nn.Sequential(\n",
    "                nn.Linear(in_features, in_features // 2),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(in_features // 2, num_classes)\n",
    "            )\n",
    "        def forward(self, x):\n",
    "            x = self.efficientnet(x)  \n",
    "            return x\n",
    "    model = CustomEfficientNet(num_classes=3)\n",
    "    return model.to(device)\n",
    "\n",
    "# ② CNN Block\n",
    "# def create_model():\n",
    "#     class CustomEfficientNet(nn.Module):\n",
    "#         def __init__(self, num_classes=3):\n",
    "#             super(CustomEfficientNet, self).__init__()\n",
    "#             self.feature_extractor = nn.Sequential(\n",
    "#                 nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),\n",
    "#                 nn.BatchNorm2d(64),\n",
    "#                 nn.ReLU(inplace=True),\n",
    "#                 nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#                 nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "#                 nn.BatchNorm2d(128),\n",
    "#                 nn.ReLU(inplace=True),\n",
    "#                 nn.Conv2d(128, 3, kernel_size=1),\n",
    "#                 nn.AdaptiveAvgPool2d((224, 224))  \n",
    "#             )\n",
    "#             self.efficientnet = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "#             in_features = self.efficientnet.classifier.in_features\n",
    "#             self.efficientnet.classifier = nn.Sequential(\n",
    "#                 nn.Linear(in_features, in_features // 2),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Dropout(0.5),\n",
    "#                 nn.Linear(in_features // 2, num_classes)\n",
    "#             )\n",
    "#         def forward(self, x):\n",
    "#             x = self.feature_extractor(x)\n",
    "#             x = self.efficientnet(x)  \n",
    "#             return x\n",
    "#     model = CustomEfficientNet(num_classes=3)\n",
    "#     return model.to(device)\n",
    "\n",
    "# ③ gabor filters + gabor_conv\n",
    "# def create_model():\n",
    "#     class CustomEfficientNet(nn.Module):\n",
    "#         def __init__(self, num_classes=3):\n",
    "#             super(CustomEfficientNet, self).__init__()\n",
    "#             self.gabor_conv = nn.Conv2d(8, 1, kernel_size=3, padding=1) \n",
    "#             self.efficientnet = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "#             self.efficientnet.conv_stem = nn.Conv2d(\n",
    "#                 4, 32, kernel_size=3, stride=2, padding=1, bias=False\n",
    "#             )\n",
    "#             in_features = self.efficientnet.classifier.in_features\n",
    "#             self.efficientnet.classifier = nn.Sequential(\n",
    "#                 nn.Linear(in_features, in_features // 2),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Dropout(0.5),\n",
    "#                 nn.Linear(in_features // 2, num_classes)\n",
    "#             )\n",
    "#         def forward(self, x, gabor_features):\n",
    "#             gabor_features = self.gabor_conv(gabor_features)  \n",
    "#             x = torch.cat((x, gabor_features), dim=1) \n",
    "#             x = self.efficientnet(x)\n",
    "#             return x\n",
    "#     model = CustomEfficientNet(num_classes=3)\n",
    "#     return model.to(device)\n",
    "\n",
    "# ④ gabor filters + CNN Block\n",
    "# def create_model():\n",
    "#     class CustomEfficientNet(nn.Module):\n",
    "#         def __init__(self, num_classes=3):\n",
    "#             super(CustomEfficientNet, self).__init__()\n",
    "#              # 自定义特征提取模块\n",
    "#             self.feature_extractor = nn.Sequential(\n",
    "#                 nn.Conv2d(9, 64, kernel_size=3, stride=2, padding=1),  \n",
    "#                 nn.BatchNorm2d(64),\n",
    "#                 nn.ReLU(inplace=True),\n",
    "#                 nn.MaxPool2d(kernel_size=2, stride=2), \n",
    "#                 nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  \n",
    "#                 nn.BatchNorm2d(128),\n",
    "#                 nn.ReLU(inplace=True),\n",
    "#                 nn.Conv2d(128, 3, kernel_size=1), \n",
    "#                 nn.AdaptiveAvgPool2d((224, 224))  \n",
    "#             )\n",
    "#             self.efficientnet = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "#             in_features = self.efficientnet.classifier.in_features\n",
    "#             self.efficientnet.classifier = nn.Sequential(\n",
    "#                 nn.Linear(in_features, in_features // 2),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Dropout(0.5),\n",
    "#                 nn.Linear(in_features // 2, num_classes)\n",
    "#             )\n",
    "#         def forward(self, x):\n",
    "#             x = self.feature_extractor(x)\n",
    "#             x = self.efficientnet(x)\n",
    "#             return x\n",
    "#     model = CustomEfficientNet(num_classes=3)\n",
    "#     return model.to(device)\n",
    "\n",
    "# 8 Gabor filters definition\n",
    "def gabor_filter():\n",
    "    frequency_values = [0.250, 0.177, 0.125, 0.088, 0.062, 0.044, 0.031, 0.022] \n",
    "    sigma_values = [4 * np.sqrt(2 * np.pi), 8 * np.pi, 8 * np.sqrt(2 * np.pi), 16 * np.pi,\n",
    "                16 * np.sqrt(2 * np.pi), 32 * np.pi, 32 * np.sqrt(2 * np.pi), 64 * np.pi] \n",
    "    gabor_filters = []\n",
    "    i = 0\n",
    "    for f in frequency_values:\n",
    "        wavelength = 1 / f\n",
    "        gabor_kernel = cv2.getGaborKernel((21, 21), 0.15*sigma_values[i], np.pi/2, wavelength, 1/np.sqrt(2), 0, ktype=cv2.CV_32F)\n",
    "        gabor_filters.append(gabor_kernel)\n",
    "        i += 1\n",
    "    return gabor_filters\n",
    "\n",
    "def gabor_filter_batch(inputs, gabor_filters, batch_size=16):\n",
    "    \"\"\"\n",
    "    Apply Gabor filters to a batch of images.\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    inputs (torch.Tensor): Input image tensor with shape [batch_size, 3, H, W].\n",
    "    gabor_filters (list): A list containing 8 Gabor kernels.\n",
    "    batch_size (int): Number of images in the batch.\n",
    "\n",
    "    Returns:\n",
    "    \n",
    "    torch.Tensor: Gabor feature tensor with shape [batch_size, 8, H, W].\n",
    "    or\n",
    "    torch.Tensor: Gabor feature tensor with shape [batch_size, 9, H, W] (concatenated with the original gray image).\n",
    "    \"\"\"\n",
    "    batch_size = batch_size\n",
    "    gabor_features = []  \n",
    "\n",
    "    for i in range(batch_size):\n",
    "        img = inputs[i].permute(1, 2, 0).cpu().numpy() \n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)  \n",
    "        gabor_responses = []\n",
    "        for kernel in gabor_filters:\n",
    "            response = cv2.filter2D(img_gray, cv2.CV_32F, kernel)  \n",
    "            gabor_responses.append(response)\n",
    "        gabor_responses = np.stack(gabor_responses, axis=0)  # [8, H, W] default 8 channels\n",
    "        # If you want to concatenate the original gray image with Gabor responses, uncomment the following line:\n",
    "        # gabor_responses = np.concatenate((np.expand_dims(img_gray, axis=0), gabor_responses), axis=0)  # [9, H, W]\n",
    "        gabor_features.append(gabor_responses)\n",
    "\n",
    "    gabor_features = np.stack(gabor_features, axis=0) \n",
    "    gabor_features = torch.tensor(gabor_features, dtype=torch.float32) \n",
    "    return gabor_features\n",
    "\n",
    "# Grad-CAM visualization function definition\n",
    "def grad_cam(model, img_tensor, target_layer):\n",
    "    model.eval()\n",
    "    img_tensor = img_tensor.to(device)\n",
    "    features = None\n",
    "    gradients = None\n",
    "\n",
    "    def forward_hook(module, input, output):\n",
    "        nonlocal features\n",
    "        features = output\n",
    "\n",
    "    def backward_hook(module, grad_in, grad_out):\n",
    "        nonlocal gradients\n",
    "        gradients = grad_out[0]\n",
    "\n",
    "    handle_forward = target_layer.register_forward_hook(forward_hook)\n",
    "    handle_backward = target_layer.register_backward_hook(backward_hook)\n",
    "\n",
    "    output = model(img_tensor)\n",
    "    pred_class = output.argmax(dim=1)\n",
    "    loss = output[0, pred_class]\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])\n",
    "    features = features[0]\n",
    "    for i in range(features.shape[0]):\n",
    "        features[i, :, :] *= pooled_gradients[i]\n",
    "\n",
    "    heatmap = features.detach().cpu().numpy().mean(axis=0)\n",
    "    heatmap = np.maximum(heatmap, 0)  \n",
    "    max_value = np.max(heatmap)\n",
    "    if max_value > 0:\n",
    "        heatmap /= max_value\n",
    "    else:\n",
    "        heatmap = np.zeros_like(heatmap)  \n",
    "\n",
    "    handle_forward.remove()\n",
    "    handle_backward.remove()\n",
    "\n",
    "    return heatmap\n",
    "\n",
    "def plot_grad_cam(img_path, model, target_layer):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, (img_size, img_size))\n",
    "    img = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))  \n",
    "    img_tensor = transform_val(img).unsqueeze(0)\n",
    "\n",
    "    heatmap = grad_cam(model, img_tensor, target_layer)\n",
    "    heatmap = cv2.resize(heatmap, img.size)  \n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "    if isinstance(img, Image.Image):  \n",
    "        img = np.array(img)  # 转换为 NumPy 数组\n",
    "    superimposed_img = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Grad-CAM\")\n",
    "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9136231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training (different models' training codes are not the same)\n",
    "# make sure to uncomment the model you want to train and comment out the others\n",
    "\n",
    "# If you want to save the model, uncomment the following line:\n",
    "\n",
    "# model_path_dir = f\"your-model-path-directory\"  # e.g., '/home/user/model'\n",
    "# current_time = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "# model_name = f\"resnet18_time{current_time}.pth\"\n",
    "# model_path = os.path.join(model_path_dir, model_name)\n",
    "\n",
    "model = create_model()\n",
    "train_dataset = datasets.ImageFolder(train_dir)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "folds = list(kf.split(range(len(train_dataset))))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 4\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "for fold, (train_idx, val_idx) in enumerate(folds):\n",
    "    print(f\"  Fold {fold+1}/5---------------------------------------------------------------------------\")\n",
    "    train_dataset = datasets.ImageFolder(train_dir)\n",
    "    train_subset = Subset(train_dataset, train_idx)\n",
    "    val_subset = Subset(train_dataset, val_idx)\n",
    "    train_subset.dataset.transform = transform_train\n",
    "    val_subset.dataset.transform = transform_val\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    for epoch in range(epochs):  \n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        # ① Default ResNet18 & ② CNN Block \n",
    "        for inputs, labels in train_loader:  \n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "        # ③ Gabor filters + gabor_conv\n",
    "        # for inputs, labels in train_loader:\n",
    "        #     gabor_features = gabor_filter_batch(inputs, gabor_filter()) # Here gabor features tensor with shape [batch_size, 8, H, W]  \n",
    "        #     inputs, gabor_features, labels = inputs.to(device).float(), gabor_features.to(device).float(), labels.to(device)  \n",
    "        #     optimizer.zero_grad()\n",
    "        #     outputs = model(inputs, gabor_features)\n",
    "        \n",
    "        # ④ Gabor filters + CNN Block\n",
    "        # for inputs, labels in train_loader:\n",
    "        #     gabor_features = gabor_filter_batch(inputs, gabor_filter()) # Here gabor features tensor with shape [batch_size, 9, H, W]  \n",
    "        #     inputs, labels = gabor_features.to(device).float(), labels.to(device) \n",
    "        #     optimizer.zero_grad()\n",
    "        #     outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "        train_acc = train_correct / train_total\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            # ① Default ResNet18 & ② CNN Block \n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device) \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "            # # ③ Gabor filters + gabor_conv\n",
    "            # for inputs, labels in val_loader:\n",
    "            #     gabor_features = gabor_filter_batch(inputs, gabor_filter()) # Here gabor features tensor with shape [batch_size, 8, H, W]  \n",
    "            #     inputs, gabor_features, labels = inputs.to(device).float(), gabor_features.to(device).float(), labels.to(device)\n",
    "            #     outputs = model(inputs, gabor_features)\n",
    "            #     loss = criterion(outputs, labels)\n",
    "            #     val_loss += loss.item()\n",
    "                \n",
    "            # ④ Gabor filters + CNN Block\n",
    "            # for inputs, labels in val_loader:   \n",
    "            #     gabor_features = gabor_filter_batch(inputs, gabor_filter()) # Here gabor features tensor with shape [batch_size, 9, H, W]  \n",
    "            #     inputs, labels = gabor_features.to(device).float(), labels.to(device)  \n",
    "            #     outputs = model(inputs)\n",
    "            #     loss = criterion(outputs, labels)\n",
    "            #     val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "            val_acc = val_correct / val_total\n",
    "        print(f\"   Epoch {epoch+1}/{epochs}, Train Loss: {train_loss/len(train_loader):.4f}, \"\n",
    "            f\"Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {val_correct/val_total:.4f}\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "# If you want to save the model, uncomment the following line:\n",
    "# torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4357c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Testing  (different models' testing codes are not the same)\n",
    "# make sure to uncomment the model you want to test and comment out the others\n",
    "\n",
    "# If you want to test the saved model, uncomment the following line:\n",
    "# make sure the model you want to test is the same as the one you trained\n",
    "# you can uncomment corresponding model definition in \"Model and Function Definition\" part and run it again\n",
    "# model_path_dir = f\"your-model-path-directory\"  # e.g., '/home/user/model'\n",
    "# model_name = f\"your-model-name.pth\" \n",
    "# model_path = os.path.join(model_path_dir, model_name)\n",
    "# model = create_model()\n",
    "# model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "file_dir = r'your-dataset-path-directory'  # e.g., '/home/user/dataset'\n",
    "test_dir = os.path.join(file_dir, 'your-testsubset-name')\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform_val)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "misclassified_images = []\n",
    "misclassified_labels = []\n",
    "misclassified_predictions = []\n",
    "\n",
    "trueclassified_images = []\n",
    "trueclassified_labels = []\n",
    "trueclassified_predictions = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # ① Default ResNet18 & ② CNN Block\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "    # ③ Gabor filters + gabor_conv\n",
    "    # for inputs, labels in test_loader:\n",
    "    #     gabor_features = gabor_filter_batch(inputs, gabor_filter())\n",
    "    #     inputs, gabor_features, labels = inputs.to(device).float(), gabor_features.to(device).float(), labels.to(device)\n",
    "    #     outputs = model(inputs, gabor_features)\n",
    "\n",
    "    # ④ Gabor filters + CNN Block\n",
    "    # for inputs, labels in test_loader:\n",
    "    #     gabor_features = gabor_filter_batch(inputs, gabor_filter())\n",
    "    #     inputs, labels = gabor_features.to(device).float(), labels.to(device)\n",
    "    #     outputs = model(inputs)\n",
    "        \n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item() \n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == predicted[i]:\n",
    "                misclassified_images.append(inputs[i].cpu())\n",
    "                misclassified_labels.append(labels[i].cpu().item())\n",
    "                misclassified_predictions.append(predicted[i].cpu().item())\n",
    "            else:\n",
    "                trueclassified_images.append(inputs[i].cpu())\n",
    "                trueclassified_labels.append(labels[i].cpu().item())\n",
    "                trueclassified_predictions.append(predicted[i].cpu().item())\n",
    "test_acc = 100. * correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74736c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing Test Results-confusion matrix and recall\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_dataset.classes)\n",
    "tp = cm[1, 1]+ cm[2, 2]\n",
    "fn = cm[1, 0]+ cm[2, 0]\n",
    "recall = tp / (tp + fn)*100 if (tp + fn) > 0 else 0\n",
    "print(f\"Recall: {recall:.2f}%\")\n",
    "plt.figure(figsize=(8, 8))\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e27ecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing Test Results-Grad-CAM visualization for misclassified images or trueclassified images\n",
    "\n",
    "combined_heatmap = np.zeros((img_size, img_size))\n",
    "target_layer = model.resnet.layer4[1].conv2\n",
    "for img_tensor in trueclassified_images: # choose misclassified_images or trueclassified_images\n",
    "    heatmap = grad_cam(model, img_tensor.unsqueeze(0).to(device), target_layer) \n",
    "    heatmap_resized = cv2.resize(heatmap, (img_size, img_size))\n",
    "    combined_heatmap += heatmap_resized\n",
    "combined_heatmap /= len(trueclassified_images) # choose misclassified_images or trueclassified_images\n",
    "combined_heatmap = np.uint8(255 * (combined_heatmap / np.max(combined_heatmap))) \n",
    "combined_heatmap = cv2.applyColorMap(combined_heatmap, cv2.COLORMAP_JET)\n",
    "img = np.ones((img_size, img_size, 3), dtype=np.uint8) * 255\n",
    "superimposed_img = cv2.addWeighted((img * 255).astype(np.uint8), 0.6, combined_heatmap, 0.4, 0)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"Combined Grad-CAM Heatmap\")\n",
    "plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8cefa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing Test Results-Grad-CAM visualization for random misclassified&trueclassified images\n",
    "\n",
    "# left is input image, right is Grad-CAM result\n",
    "max_num = 10 # choose the most number of images to show at once\n",
    "class_names = test_dataset.classes\n",
    "num_images_to_show = min(max_num, len(misclassified_images))  \n",
    "plt.figure(figsize=(15, 30))\n",
    "for i in range(num_images_to_show):\n",
    "    j = i + max_num*1  # adjust \"*num\" to show more images\n",
    "    img = misclassified_images[j]\n",
    "    img = img.permute(1, 2, 0).numpy()  \n",
    "    img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "    img = np.clip(img, 0, 1) \n",
    "    heatmap = grad_cam(model, misclassified_images[j].unsqueeze(0).to(device), target_layer)\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    superimposed_img = cv2.addWeighted((img * 255).astype(np.uint8), 0.6, heatmap, 0.4, 0)\n",
    "\n",
    "    plt.subplot(num_images_to_show, 2, 2 * i + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"{j}:True: {class_names[misclassified_labels[j]]}, Pred: {class_names[misclassified_predictions[j]]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(num_images_to_show, 2, 2 * i + 2)\n",
    "    plt.imshow(cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Grad-CAM\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ST5188",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
